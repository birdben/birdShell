input {
    kafka {
        # 指定Zookeeper集群地址
        zk_connect => "hadoop1:2181,hadoop2:2181,hadoop3:2181"
        # 指定当前消费者的group_id，group_id不能和其他logstash消费者相同，否则同时启动多个Logstash消费者offset会被覆盖
        group_id => "logstash_java"
        # 指定消费的Topic
        topic_id => "java_log"
        # 指定消费的内容类型（默认是json）
        codec => "json"
        # 设置Consumer消费者从Kafka最开始的消息开始消费，必须结合"auto_offset_reset => smallest"一起使用
        reset_beginning => true
        # 设置如果Consumer消费者还没有创建offset或者offset非法，从最开始的消息开始消费还是从最新的消息开始消费
        auto_offset_reset => "smallest"
    }
}

filter {
    grok {
        match => {
            "message" => "%{JAVA_LOGS}"
        }
    }
    metrics {
        # 定义metrics计数器数据保存的字段名 field_name的值就是上面Grok表达式解析出来的字段名
        meter => [ "event_%{file_name}" ]
        # 给该metrics添加tag标签，用于区分metrics
        add_tag => [ "metric" ]
        # 每隔5分钟统计一次（测试环境可以适当改小）
        flush_interval => 300
        # 每隔5分钟（flush_interval + 1秒）清空计数器（测试环境可以适当改小）
        clear_interval => 301
        # 10秒内的message数据才统计，避免延迟
        ignore_older_than => 10
    }
    if "metric" in [tags] {
        ruby {
            # code是定义metrics的过滤规则，满足什么条件删除metric event日志
            # 如果code为空，就是metric event不会被cancel，那么最终metric event会output到elasticsearch/stdout/email，如果不想每个metric event都触发告警事件，就只能通过ruby插件的code添加ruby代码来控制metric event的取消条件
            # code => ""
            # 如果RiskTask事件不为空并且JdUploadTask事件的count大于1条，就忽略此事件(即不发送任何消息)。
            code => "event.cancel if event['event_RiskTask'] != nil && event['event_RiskTask']['count'] > 1"
        }
    }
    date {
        match => ["timestamp", "YYYY-MM-dd HH:mm:ss"]
        target => "@timestamp"
    }
    if "_grokparsefailure" in [tags] {
        drop { }
    }
}

output {
    stdout {
        codec => rubydebug
    }
    if "metric" in [tags] {
        # 测试环境建议注释掉邮件发送，否则邮箱容易爆炸
        email {
            # stmp服务器地址
            address => "smtpdm.aliyun.com"
            # 发件人邮箱地址
            username => "service@post.XXX.com"
            # 发件人邮箱密码
            password => "123456"
            # 发件人邮箱
            from => "service@post.XXX.com"
            # 收件人邮箱
            to => "birdben@XXX.com"
            # 邮件主题
            subject => "告警：风控任务未执行"
            # 邮件内容
            htmlbody => "告警内容：com.yunyu.birdben.task.RiskTask没有执行"
        }
    } else {
        # 带有metric Tag的数据只是用于告警，不应该存储与ES索引中
        elasticsearch {
            codec => "json"
            hosts => ["hadoop1:9200", "hadoop2:9200", "hadoop3:9200"]
            index => "java_logs_index_%{+YYYY.MM.dd}"
            document_type => "%{type}"
            template => "/usr/local/elasticsearch/template/java_logs_template.json"
            template_name => "java_logs_template"
            template_overwrite => true
            workers => 1
            flush_size => 20000
            idle_flush_time => 10
        }
    }
}
