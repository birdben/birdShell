agentX.sources = node-sink go-rpserver-sink go-rpproxy-sink
agentX.channels = chNode chGo
agentX.sinks = node-kafka-sink go-kafka-sink
#agentX.sinks = flume-hdfs-sink flume-kafka-sink

agentX.sources.node-sink.channels = chNode
agentX.sources.node-sink.type = avro
agentX.sources.node-sink.bind = flume_collector_server2
agentX.sources.node-sink.port = 41414
agentX.sources.node-sink.threads = 8

agentX.sources.go-rpserver-sink.channels = chGo
agentX.sources.go-rpserver-sink.type = avro
agentX.sources.go-rpserver-sink.bind = flume_collector_server2
agentX.sources.go-rpserver-sink.port = 41415
agentX.sources.go-rpserver-sink.threads = 8

agentX.sources.go-rpproxy-sink.channels = chGo
agentX.sources.go-rpproxy-sink.type = avro
agentX.sources.go-rpproxy-sink.bind = flume_collector_server2
agentX.sources.go-rpproxy-sink.port = 41416
agentX.sources.go-rpproxy-sink.threads = 8

#定义拦截器，为消息添加时间戳和Host地址
agentX.sources.node-sink.interceptors = i1 i2
agentX.sources.node-sink.interceptors.i1.type = timestamp
agentX.sources.node-sink.interceptors.i2.type = regex_extractor
agentX.sources.node-sink.interceptors.i2.regex = "name":"(.*?)"
agentX.sources.node-sink.interceptors.i2.serializers = s1
agentX.sources.node-sink.interceptors.i2.serializers.s1.name = type_name

agentX.sources.go-rpserver-sink.interceptors = go-rpserver
agentX.sources.go-rpserver-sink.interceptors.go-rpserver.type = static
agentX.sources.go-rpserver-sink.interceptors.go-rpserver.key = type
agentX.sources.go-rpserver-sink.interceptors.go-rpserver.value = rpserver

agentX.sources.go-rpproxy-sink.interceptors = go-rpproxy
agentX.sources.go-rpproxy-sink.interceptors.go-rpproxy.type = static
agentX.sources.go-rpproxy-sink.interceptors.go-rpproxy.key = type
agentX.sources.go-rpproxy-sink.interceptors.go-rpproxy.value = rpproxy

agentX.channels.chNode.type = memory
agentX.channels.chNode.capacity = 1000
agentX.channels.chNode.transactionCapacity = 100

agentX.channels.chGo.type = memory
agentX.channels.chGo.capacity = 1000
agentX.channels.chGo.transactionCapacity = 100

#agentX.sinks.flume-hdfs-sink.type = hdfs
#agentX.sinks.flume-hdfs-sink.channel = chX
#agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://hadoop1:9000/flume/events/%{type_name}/%Y%m
#agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream
#agentX.sinks.flume-hdfs-sink.hdfs.filePrefix = events-
#agentX.sinks.flume-hdfs-sink.hdfs.rollInterval = 300
#agentX.sinks.flume-hdfs-sink.hdfs.rollSize = 0
#agentX.sinks.flume-hdfs-sink.hdfs.rollCount = 300

agentX.sinks.node-kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
agentX.sinks.node-kafka-sink.topic = adlog
agentX.sinks.node-kafka-sink.brokerList = kafka1:9092
agentX.sinks.node-kafka-sink.requiredAcks = 1
agentX.sinks.node-kafka-sink.batchSize = 20
agentX.sinks.node-kafka-sink.channel = chNode

agentX.sinks.go-kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
agentX.sinks.go-kafka-sink.topic = golog
agentX.sinks.go-kafka-sink.brokerList = kafka1:9092
agentX.sinks.go-kafka-sink.requiredAcks = 1
agentX.sinks.go-kafka-sink.batchSize = 20
agentX.sinks.go-kafka-sink.channel = chGo
# 开启Flume写入Header，默认是使用StringSerializer方式序列化Message的
# 默认是只将body写入到Kafka的，设置为true会根据Flume Avro binary格式来存储Event
# org.apache.kafka.common.serialization.StringSerializer
# org.apache.kafka.common.serialization.ByteArraySerializer
agentX.sinks.go-kafka-sink.useFlumeEventFormat = true
